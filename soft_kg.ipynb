{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4feb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb \n",
    "import torch\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import logging\n",
    "from uuid import UUID\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0f4e464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nathaniellaster/projects/soft_kg_example_nb/.venv/lib/python3.12/site-packages/sql/parse.py:338: SyntaxWarning: invalid escape sequence '\\:'\n",
      "  \"\"\"\n",
      "/Users/nathaniellaster/projects/soft_kg_example_nb/.venv/lib/python3.12/site-packages/sql/parse.py:368: SyntaxWarning: invalid escape sequence '\\:'\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Tip: You may define configurations in /Users/nathaniellaster/projects/soft_kg_example_nb/pyproject.toml or /Users/nathaniellaster/.jupysql/config. </span>"
      ],
      "text/plain": [
       "Tip: You may define configurations in /Users/nathaniellaster/projects/soft_kg_example_nb/pyproject.toml or /Users/nathaniellaster/.jupysql/config. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Please review our <a href='https://jupysql.ploomber.io/en/latest/api/configuration.html#loading-from-a-file'>configuration guideline</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Did not find user configurations in /Users/nathaniellaster/projects/soft_kg_example_nb/pyproject.toml.</span>"
      ],
      "text/plain": [
       "Did not find user configurations in /Users/nathaniellaster/projects/soft_kg_example_nb/pyproject.toml."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Connecting to &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Connecting to 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Success</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+---------+\n",
       "| Success |\n",
       "+---------+\n",
       "+---------+"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext sql\n",
    "%sql duckdb://\n",
    "\n",
    "%sql INSTALL vss\n",
    "%sql LOAD vss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef01fccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMENSIONS = 768\n",
    "EMBEDDING_MODEL = \"BAAI/bge-base-en-v1.5\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c5038f",
   "metadata": {},
   "source": [
    "# Basic Table Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28287f05",
   "metadata": {},
   "source": [
    "Create the relations table, which will store shuffle masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "315410e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "+-------+"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "CREATE TABLE IF NOT EXISTS relations (\n",
    "    id TEXT PRIMARY KEY, \n",
    "    shuffle_mask FLOAT[{{DIMENSIONS}}],\n",
    "    projection_weights FLOAT[{{DIMENSIONS}}]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335e485",
   "metadata": {},
   "source": [
    "Create the entities table, which will store the entity data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8527aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "+-------+"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "CREATE TABLE IF NOT EXISTS entities (\n",
    "    id TEXT PRIMARY KEY,  \n",
    "    version INTEGER,\n",
    "    embedding FLOAT[{{DIMENSIONS}}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3b9acc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <thead>\n",
       "        <tr>\n",
       "            <th>Count</th>\n",
       "        </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "+-------+\n",
       "| Count |\n",
       "+-------+\n",
       "+-------+"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql \n",
    "CREATE TABLE IF NOT EXISTS adjacency (\n",
    "    head_id TEXT, \n",
    "    tail_id TEXT, \n",
    "    relation_id TEXT,\n",
    "    PRIMARY KEY (head_id, tail_id, relation_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b845b9f7",
   "metadata": {},
   "source": [
    "# Embedding Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "319040bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c74d65",
   "metadata": {},
   "source": [
    "# Database Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cdc1cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_entity(term: str):\n",
    "    result = %sql SELECT embedding, version FROM entities WHERE id = '{{term}}'\n",
    "    if result:\n",
    "        logging.info(f\"Found Result: {term}\")\n",
    "        d = result.dict()\n",
    "        emb = np.array(d['embedding'][0])\n",
    "        return torch.from_numpy(emb).clone(), d['version'][0]\n",
    "    else:\n",
    "        logging.info(f\"Cold Start: Embedding {term}\")\n",
    "        emb = embedding_model.encode(term)\n",
    "        emb_list = emb.tolist()\n",
    "        %sql INSERT INTO entities (id, embedding, version) VALUES ('{{term}}', {{emb_list}}, 1)\n",
    "        return torch.from_numpy(emb).clone(), 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c05528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_relation_with_weights(rel_id):\n",
    "    \"\"\"\n",
    "    Fetches (Permutation Mask, Projection Weights).\n",
    "    If new, initializes Mask to Random and Weights to 1.0 (Strict).\n",
    "    \"\"\"\n",
    "    # 1. Check if relation exists\n",
    "    result = %sql SELECT shuffle_mask, projection_weights FROM relations WHERE id = '{{rel_id}}'\n",
    "    \n",
    "    if result:\n",
    "        d = result.dict()\n",
    "        mask = np.array(d['shuffle_mask'][0])\n",
    "        \n",
    "        # Handle case where weights might be null (legacy data)\n",
    "        if d.get('projection_weights') and d['projection_weights'][0]:\n",
    "            weights = np.array(d['projection_weights'][0])\n",
    "        else:\n",
    "            weights = np.ones(DIMENSIONS) # Default to 1.0\n",
    "            \n",
    "        return (\n",
    "            torch.from_numpy(mask).long().clone(), \n",
    "            torch.from_numpy(weights).float().clone()\n",
    "        )\n",
    "    else:\n",
    "        # 2. Create New\n",
    "        mask = np.random.permutation(DIMENSIONS) # Random Shuffle\n",
    "        weights = np.ones(DIMENSIONS)            # Strict Attention (1.0)\n",
    "        \n",
    "        mask_list = mask.tolist()\n",
    "        weights_list = weights.tolist()\n",
    "        \n",
    "        # Note: You might need to ALTER TABLE relations ADD COLUMN projection_weights FLOAT[768]\n",
    "        # if using the old schema.\n",
    "        %sql INSERT INTO relations (id, shuffle_mask, projection_weights) VALUES ('{{rel_id}}', {{mask_list}}, {{weights_list}})\n",
    "        \n",
    "        return (\n",
    "            torch.from_numpy(mask).long().clone(), \n",
    "            torch.from_numpy(weights).float().clone()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef5eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(ent_id: UUID):\n",
    "    result = %sql SELECT head_id, relation_id, tail_id FROM adjacency WHERE head_id = '{{ent_id}}' OR tail_id = '{{ent_id}}' \n",
    "    return list(result.dicts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "482f0cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cas_update(updates):\n",
    "    for ent_id, (new_emb, old_ver) in updates.items():\n",
    "        emb = new_emb.detach().numpy().astype(np.float32).tolist()\n",
    "        %sql UPDATE entities SET embedding = {{emb}}, version = {{old_ver + 1}} WHERE id = '{{ent_id}}' and version = {{old_ver}}\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "521d13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cas_update_relation(rel_id, new_weights):\n",
    "    \"\"\"Updates the projection weights for a relation.\"\"\"\n",
    "    w_list = new_weights.detach().numpy().tolist()\n",
    "    %sql UPDATE relations SET projection_weights = {{w_list}} WHERE id = '{{rel_id}}'\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9367cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edge(head_id: UUID, relation_id: UUID, tail_id: UUID):\n",
    "    %sql INSERT INTO adjacency (head_id, relation_id, tail_id) VALUES ('{{head_id}}', '{{relation_id}}', '{{tail_id}}')\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435a1f18",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# Reshuffle Core\n",
    "# ==========================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c0e445e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingReshuffleModule(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch Logic Core. \n",
    "    Now implements Automatic Symmetric Tension in the forward pass.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embeddings_dict, relations_dict, weights_dict):\n",
    "        super().__init__()\n",
    "        self.ent_map = {k: i for i, k in enumerate(embeddings_dict.keys())}\n",
    "        self.rel_map = {k: i for i, k in enumerate(relations_dict.keys())}\n",
    "\n",
    "        # 1. Load Entities\n",
    "        if embeddings_dict:\n",
    "            self.entities = nn.Parameter(torch.stack(list(embeddings_dict.values())))\n",
    "        else:\n",
    "            self.entities = nn.Parameter(torch.empty(0, DIMENSIONS))\n",
    "\n",
    "        # 2. Load Relations & Pre-compute Inverses\n",
    "        if relations_dict:\n",
    "            self.shuffles = torch.stack(list(relations_dict.values()))\n",
    "            # AUTOMATIC: Pre-compute inverse masks (The \"Un-shuffle\")\n",
    "            # If Forward is A -> B, Inverse is B -> A\n",
    "            self.inv_shuffles = torch.argsort(self.shuffles, dim=1)\n",
    "\n",
    "            # --- Learnable Projection Weights ---\n",
    "            # We initialize them to 1.0 (Full Attention).\n",
    "            # The system will learn to lower them to 0.0 for irrelevant features.\n",
    "            # num_rels = len(relations_dict)\n",
    "            # self.rel_weights = nn.Parameter(torch.ones(num_rels, DIMENSIONS))\n",
    "            self.rel_weights = nn.Parameter(torch.stack(list(weights_dict.values())))\n",
    "\n",
    "        else:\n",
    "            self.shuffles = torch.empty(0, DIMENSIONS, dtype=torch.long)\n",
    "            self.inv_shuffles = torch.empty(0, DIMENSIONS, dtype=torch.long)\n",
    "            self.rel_weights = nn.Parameter(torch.empty(0, DIMENSIONS))\n",
    "\n",
    "    def forward(self, h_idx, r_idx, t_idx):\n",
    "        \"\"\"\n",
    "        Calculates Symmetric Tension.\n",
    "        Minimizing this value forces the embeddings to satisfy the relationship \n",
    "        bi-directionally (Structural Equality).\n",
    "        \"\"\"\n",
    "        h = self.entities[h_idx]\n",
    "        t = self.entities[t_idx]\n",
    "        \n",
    "        # --- Apply Projection (Focus) ---\n",
    "        # Fetch the weight mask for this specific relation\n",
    "        w = self.rel_weights[r_idx]\n",
    "        \n",
    "        # Project both entities into the \"Relation Subspace\"\n",
    "        # If w[i] is near 0, that dimension effectively vanishes.\n",
    "        h_proj = h * w\n",
    "        t_proj = t * w\n",
    "\n",
    "        # 1. Forward Logic: Head vs Shuffled Tail\n",
    "        # \"Does Head look like a permutation of Tail?\"\n",
    "        mask = self.shuffles[r_idx]\n",
    "        t_shuffled = t_proj[mask]\n",
    "        fwd_tension = torch.relu(h_proj - t_shuffled).sum()\n",
    "\n",
    "        # 2. Inverse Logic: Tail vs Un-shuffled Head\n",
    "        # \"Does Tail look like the inverse permutation of Head?\"\n",
    "        inv_mask = self.inv_shuffles[r_idx]\n",
    "        h_unshuffled = h_proj[inv_mask]\n",
    "        inv_tension = torch.relu(t_proj - h_unshuffled).sum()\n",
    "\n",
    "        # C. Regularization (The \"Anti-Collapse\" Term)\n",
    "        # We penalize weights that are too small to prevent the \"Zero Solution.\"\n",
    "        # This keeps the system honest.\n",
    "        # Logic: maximize sum(w) -> minimize -sum(w)\n",
    "        reg_loss = -torch.sum(w) * 0.05\n",
    "\n",
    "        # 3. Combine\n",
    "        # We average them so the optimizer cares about both directions equally.\n",
    "        return ((fwd_tension + inv_tension) / 2.0) + reg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5f70ed",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# LAYER 3: THE WORKER (Ripple Update)\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b1b11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RippleWorker:\n",
    "    \"\"\"\n",
    "    Stateless worker performing Local Relaxation.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_fact(self, h_id, r_id, t_id, stiffness=0.5, steps=50):\n",
    "        \"\"\"The Optimistic Ripple Update Algorithm (Unchanged)\"\"\"\n",
    "        print(f\"Worker: Updating {h_id} --[{r_id}]--> {t_id} (Stiffness: {stiffness})\")\n",
    "\n",
    "        # 1. Fetch Active Set\n",
    "        active_ids = {h_id, t_id}\n",
    "        neighbors = get_neighbors(h_id) + get_neighbors(t_id)\n",
    "        for n in neighbors:\n",
    "            active_ids.add(n['head_id'])\n",
    "            active_ids.add(n['tail_id'])\n",
    "\n",
    "        # 2. Fetch Vectors & Versions\n",
    "        local_embs = {}\n",
    "        local_vers = {}\n",
    "        local_rels = {}\n",
    "        local_weights = {}\n",
    "\n",
    "        # Helper to load context\n",
    "        def load_context(eid=None, rid=None):\n",
    "            if eid and eid not in local_embs:\n",
    "                e, v = get_or_create_entity(eid)\n",
    "                local_embs[eid] = e\n",
    "                local_vers[eid] = v\n",
    "            if rid and rid not in local_rels:\n",
    "                mask, w = get_or_create_relation_with_weights(rid)\n",
    "                local_rels[rid] = mask\n",
    "                local_weights[rid] = w\n",
    "\n",
    "        # Load primary fact\n",
    "        load_context(eid=h_id)\n",
    "        load_context(eid=t_id)\n",
    "        load_context(rid=r_id)\n",
    "        \n",
    "        # Load neighbors\n",
    "        for n in neighbors:\n",
    "            load_context(eid=n['head_id'])\n",
    "            load_context(eid=n['tail_id'])\n",
    "            load_context(rid=n['relation_id'])\n",
    "\n",
    "        # 3. Initialize Compute\n",
    "        model = StreamingReshuffleModule(local_embs, local_rels, local_weights)\n",
    "\n",
    "        # Prepare Indices\n",
    "        h_idx = torch.tensor(model.ent_map[h_id])\n",
    "        t_idx = torch.tensor(model.ent_map[t_id])\n",
    "        r_idx = torch.tensor(model.rel_map[r_id])\n",
    "        \n",
    "        anchor_embs = model.entities.clone().detach() # Elasticity Anchors\n",
    "\n",
    "        # --- 3. THE TRAINING LOOP (Alternating Minimization) ---\n",
    "        \n",
    "        # PHASE 1: FIT (Move Entities, Freeze Weights)\n",
    "        # Logic: \"Assuming the rules are strict, can we fit the data?\"\n",
    "        model.entities.requires_grad = True\n",
    "        model.rel_weights.requires_grad = False\n",
    "        \n",
    "        optimizer_ent = optim.SGD([model.entities], lr=0.1)\n",
    "\n",
    "        for i in range(steps // 2):\n",
    "            optimizer_ent.zero_grad()\n",
    "            \n",
    "            # Primary Tension\n",
    "            loss = model(h_idx, r_idx, t_idx)\n",
    "            \n",
    "            # Anchor Loss (Stay close to previous state)\n",
    "            loss_anchor = torch.sum((model.entities - anchor_embs) ** 2)\n",
    "            \n",
    "            # Neighbor Constraint (Don't break existing edges)\n",
    "            loss_neighbor = 0\n",
    "            for n in neighbors:\n",
    "                ni_h = model.ent_map[n['head_id']]\n",
    "                ni_t = model.ent_map[n['tail_id']]\n",
    "                ni_r = model.rel_map[n['relation_id']]\n",
    "                loss_neighbor += model(torch.tensor(ni_h), torch.tensor(ni_r), torch.tensor(ni_t))\n",
    "            \n",
    "            total_loss = loss + (stiffness * loss_anchor) + (0.1 * loss_neighbor)\n",
    "            total_loss.backward()\n",
    "            optimizer_ent.step()\n",
    "        \n",
    "        # PHASE 2: RELAX (Move Weights, Freeze Entities)\n",
    "        # Logic: \"If we still have tension, the rule must be too strict. Loosen it.\"\n",
    "        model.entities.requires_grad = False\n",
    "        model.rel_weights.requires_grad = True\n",
    "        \n",
    "        # Lower learning rate for weights to prevent collapse\n",
    "        optimizer_rel = optim.SGD([model.rel_weights], lr=0.01)\n",
    "\n",
    "        for i in range(steps // 2):\n",
    "            optimizer_rel.zero_grad()\n",
    "            \n",
    "            # Recalculate Tension (Same formula)\n",
    "            loss = model(h_idx, r_idx, t_idx)\n",
    "            \n",
    "            # We also care about neighbors! \n",
    "            # If we relax the rule for Vader, we relax it for everyone.\n",
    "            # We must check if relaxing hurts other facts using this same relation.\n",
    "            loss_neighbor = 0\n",
    "            for n in neighbors:\n",
    "                if n['relation_id'] == r_id: # Only check relevant neighbors\n",
    "                    ni_h = model.ent_map[n['head_id']]\n",
    "                    ni_t = model.ent_map[n['tail_id']]\n",
    "                    ni_r = model.rel_map[n['relation_id']]\n",
    "                    loss_neighbor += model(torch.tensor(ni_h), torch.tensor(ni_r), torch.tensor(ni_t))\n",
    "\n",
    "            # Note: Reg_loss is already inside model.forward()\n",
    "            total_loss = loss + (0.1 * loss_neighbor)\n",
    "            total_loss.backward()\n",
    "            optimizer_rel.step()\n",
    "            \n",
    "            # Clamp weights to keep them physical [0.0, 1.0]\n",
    "            with torch.no_grad():\n",
    "                model.rel_weights.clamp_(0.0, 1.0)\n",
    "        \n",
    "        \n",
    "        # --- 4. CAS Update (Commit Changes) ---\n",
    "        \n",
    "        # A. Commit Entities\n",
    "        updates = {}\n",
    "        keys = list(local_embs.keys())\n",
    "        for i, eid in enumerate(keys):\n",
    "            updates[eid] = (model.entities[i], local_vers[eid])\n",
    "        \n",
    "        ent_success = cas_update(updates)\n",
    "        \n",
    "        # B. Commit Relation Weights\n",
    "        # We only update the relation we focused on (r_id) to avoid race conditions on others\n",
    "        new_w = model.rel_weights[model.rel_map[r_id]]\n",
    "        rel_success = cas_update_relation(r_id, new_w)\n",
    "        \n",
    "        if ent_success and rel_success:\n",
    "            # Only add the edge if both commits worked\n",
    "            add_edge(h_id, r_id, t_id)\n",
    "            print(\"  -> Update Committed (Entities & Weights).\")\n",
    "        else:\n",
    "            print(\"  -> Write Conflict. Retrying needed.\")\n",
    "\n",
    "    def reject_fact(self, h_id, r_id, t_id, stiffness=0.5, steps=50, margin=10.0):\n",
    "        \"\"\"\n",
    "        Negative Constraint: Learns that h --[r]--> t is FALSE.\n",
    "        Uses Max-Margin Loss to push embeddings apart.\n",
    "        Strategy: Updates Entities Only (Locks Weights).\n",
    "        \"\"\"\n",
    "        print(f\"Worker: REJECTING {h_id} --[{r_id}]--> {t_id} (Target Margin: {margin})\")\n",
    "\n",
    "        # --- 1. Load Context ---\n",
    "        # active_ids = {h_id, t_id}\n",
    "        neighbors = get_neighbors(h_id) + get_neighbors(t_id)\n",
    "        \n",
    "        local_embs = {}\n",
    "        local_vers = {}\n",
    "        local_rels = {}\n",
    "        local_weights = {}\n",
    "\n",
    "        def load_context(eid=None, rid=None):\n",
    "            if eid and eid not in local_embs:\n",
    "                e, v = get_or_create_entity(eid)\n",
    "                local_embs[eid] = e\n",
    "                local_vers[eid] = v\n",
    "            if rid and rid not in local_rels:\n",
    "                mask, w = get_or_create_relation_with_weights(rid)\n",
    "                local_rels[rid] = mask\n",
    "                local_weights[rid] = w\n",
    "\n",
    "        load_context(eid=h_id)\n",
    "        load_context(eid=t_id)\n",
    "        load_context(rid=r_id)\n",
    "        for n in neighbors:\n",
    "            load_context(eid=n['head_id'])\n",
    "            load_context(eid=n['tail_id'])\n",
    "            load_context(rid=n['relation_id'])\n",
    "\n",
    "        # --- 2. Initialize Physics Engine ---\n",
    "        model = StreamingReshuffleModule(local_embs, local_rels, local_weights)\n",
    "        \n",
    "        h_idx = torch.tensor(model.ent_map[h_id])\n",
    "        t_idx = torch.tensor(model.ent_map[t_id])\n",
    "        r_idx = torch.tensor(model.rel_map[r_id])\n",
    "        \n",
    "        anchor_embs = model.entities.clone().detach()\n",
    "\n",
    "        # --- 3. THE REJECTION LOOP ---\n",
    "        # We LOCK weights. We only move entities to satisfy the constraint.\n",
    "        model.rel_weights.requires_grad = False\n",
    "        model.entities.requires_grad = True\n",
    "        \n",
    "        optimizer = optim.SGD([model.entities], lr=0.1)\n",
    "\n",
    "        for i in range(steps):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Calculate current tension (How true is it?)\n",
    "            tension_val = model(h_idx, r_idx, t_idx)\n",
    "            \n",
    "            # --- CONTRASTIVE LOSS ---\n",
    "            # We want tension > margin. \n",
    "            # If tension is 2.0 and margin is 10.0, loss is 8.0.\n",
    "            # If tension is 15.0, loss is 0.\n",
    "            loss_reject = torch.relu(margin - tension_val)\n",
    "            \n",
    "            # Standard Constraints (Anchors + Neighbors)\n",
    "            # Crucial: We must push 'h' away from 't', but keep it connected to its other friends.\n",
    "            loss_anchor = torch.sum((model.entities - anchor_embs) ** 2)\n",
    "            \n",
    "            loss_neighbor = 0\n",
    "            for n in neighbors:\n",
    "                ni_h = model.ent_map[n['head_id']]\n",
    "                ni_t = model.ent_map[n['tail_id']]\n",
    "                ni_r = model.rel_map[n['relation_id']]\n",
    "                # Minimize neighbor tension (keep valid facts valid)\n",
    "                loss_neighbor += model(torch.tensor(ni_h), torch.tensor(ni_r), torch.tensor(ni_t))\n",
    "\n",
    "            # Total Loss\n",
    "            loss = loss_reject + (stiffness * loss_anchor) + (0.1 * loss_neighbor)\n",
    "            \n",
    "            if loss_reject.item() == 0:\n",
    "                # Early stopping if we pushed them far enough apart\n",
    "                break\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # --- 4. CAS Update (Entities Only) ---\n",
    "        updates = {}\n",
    "        keys = list(local_embs.keys())\n",
    "        for i, eid in enumerate(keys):\n",
    "            updates[eid] = (model.entities[i], local_vers[eid])\n",
    "\n",
    "        if cas_update(updates):\n",
    "            # If this edge existed in adjacency, we should delete it.\n",
    "            # For now, we assume this is just correcting the vector space.\n",
    "            print(\"  -> Rejection Committed.\")\n",
    "        else:\n",
    "            print(\"  -> Write Conflict. Retrying needed.\")\n",
    "\n",
    "    def trace(self, h_id, r_id, t_id):\n",
    "        \"\"\"\n",
    "        Traceability Engine.\n",
    "        Returns Confidence, Tension, and Subspace Usage.\n",
    "        \"\"\"\n",
    "        # 1. Load Minimal Context\n",
    "        h, _ = get_or_create_entity(h_id)\n",
    "        t, _ = get_or_create_entity(t_id)\n",
    "        mask, w = get_or_create_relation_with_weights(r_id)\n",
    "        \n",
    "        # 2. Setup Temporary Model\n",
    "        # (We bypass the dict overhead for speed here)\n",
    "        model = StreamingReshuffleModule(\n",
    "            {h_id: h, t_id: t}, \n",
    "            {r_id: mask}, \n",
    "            {r_id: w}\n",
    "        )\n",
    "        \n",
    "        h_idx = torch.tensor(0) # head is first\n",
    "        t_idx = torch.tensor(1) # tail is second\n",
    "        r_idx = torch.tensor(0) # relation is first\n",
    "\n",
    "        # 3. Compute Metrics\n",
    "        with torch.no_grad():\n",
    "            # Raw Tension (Energy)\n",
    "            raw_tension = model(h_idx, r_idx, t_idx).item()\n",
    "            \n",
    "            # Subspace Analysis\n",
    "            # How \"strict\" is this rule? \n",
    "            # If sum(w) is low, the rule is weak/vague.\n",
    "            active_mass = torch.sum(w).item()\n",
    "            sparsity = active_mass / DIMENSIONS\n",
    "            \n",
    "            # Normalized Tension (Error per Active Dimension)\n",
    "            # If we only look at 10 dimensions, an error of 5.0 is huge.\n",
    "            # If we look at 768 dimensions, an error of 5.0 is tiny.\n",
    "            if active_mass > 0:\n",
    "                avg_tension = raw_tension / active_mass\n",
    "            else:\n",
    "                avg_tension = raw_tension # Avoid div/0\n",
    "                \n",
    "            # Confidence Score (Sigmoid-like decay)\n",
    "            # High tension -> Low Confidence\n",
    "            confidence = 1.0 / (1.0 + (avg_tension * 10))\n",
    "\n",
    "        return {\n",
    "            \"result\": confidence > 0.5,\n",
    "            \"confidence\": round(confidence, 4),\n",
    "            \"tension\": round(raw_tension, 4),\n",
    "            \"sparsity\": round(sparsity, 4) # 1.0 = Strict, 0.1 = Very Fuzzy\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1771576d",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# LAYER 4: THE INTERFACE (API Simulation)\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c653087",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentInterface:\n",
    "    \"\"\"Simulates the API Gateway.\"\"\"\n",
    "\n",
    "    def __init__(self, worker):\n",
    "        self.worker = worker\n",
    "\n",
    "    def ingest(self, json_payload):\n",
    "        \"\"\"Implementation of POST /ingest\"\"\"\n",
    "        data = json.loads(json_payload)\n",
    "        for event in data[\"events\"]:\n",
    "            if event[\"type\"] == \"FACT\":\n",
    "                self.worker.process_fact(\n",
    "                    event[\"h\"],\n",
    "                    event[\"r\"],\n",
    "                    event[\"t\"],\n",
    "                    stiffness=event.get(\"stiffness\", 0.5),\n",
    "                )\n",
    "            elif event[\"type\"] == \"NEGATION\":\n",
    "                self.worker.reject_fact(\n",
    "                    event[\"h\"],\n",
    "                    event[\"r\"],\n",
    "                    event[\"t\"],\n",
    "                    stiffness=event.get(\"stiffness\", 0.5),\n",
    "                    margin=event.get(\"margin\", 10.0) # Default margin\n",
    "                )\n",
    "\n",
    "    def query(self, json_payload):\n",
    "        \"\"\"Implementation of POST /reason\"\"\"\n",
    "        data = json.loads(json_payload)\n",
    "        \n",
    "        if data.get(\"trace\"):\n",
    "            return self.worker.trace(\n",
    "                data[\"head\"], \n",
    "                data[\"relation\"], \n",
    "                data[\"tail\"]\n",
    "            )\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580c4578",
   "metadata": {},
   "source": [
    "# ==========================================\n",
    "# EXECUTION DEMO\n",
    "# =========================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5eba05",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c95c8295",
   "metadata": {},
   "outputs": [],
   "source": [
    "worker = RippleWorker()\n",
    "api = AgentInterface(worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f43062",
   "metadata": {},
   "source": [
    "## 2. Ingest Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4192fea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Ingestion Stream ---\n",
      "Worker: Updating Service_A --[depends_on]--> Lib_Foo (Stiffness: 1.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Update Committed (Entities & Weights).\n",
      "Worker: Updating Lib_Foo --[has_status]--> Vulnerable (Stiffness: 1.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Update Committed (Entities & Weights).\n",
      "Worker: Updating Service_A --[has_risk]--> High (Stiffness: 0.5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> Update Committed (Entities & Weights).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 2. Ingestion Stream ---\")\n",
    "payload = json.dumps(\n",
    "    {\n",
    "        \"events\": [\n",
    "            # Fact 1: Strong Truth\n",
    "            {\n",
    "                \"type\": \"FACT\",\n",
    "                \"h\": \"Service_A\",\n",
    "                \"r\": \"depends_on\",\n",
    "                \"t\": \"Lib_Foo\",\n",
    "                \"stiffness\": 1.0,\n",
    "            },\n",
    "            # Fact 2: Strong Truth\n",
    "            {\n",
    "                \"type\": \"FACT\",\n",
    "                \"h\": \"Lib_Foo\",\n",
    "                \"r\": \"has_status\",\n",
    "                \"t\": \"Vulnerable\",\n",
    "                \"stiffness\": 1.0,\n",
    "            },\n",
    "            # Fact 3: Agent Hypothesis (Weaker stiffness)\n",
    "            {\n",
    "                \"type\": \"FACT\",\n",
    "                \"h\": \"Service_A\",\n",
    "                \"r\": \"has_risk\",\n",
    "                \"t\": \"High\",\n",
    "                \"stiffness\": 0.5,\n",
    "            },\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "api.ingest(payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee59c3a4",
   "metadata": {},
   "source": [
    "## 3. Query and Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "16ae6a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 3. Reasoning & Traceability ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Result: {'result': True, 'confidence': 1.4247, 'tension': -22.8904, 'sparsity': 0.9999}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<span style=\"None\">Running query in &#x27;duckdb://&#x27;</span>"
      ],
      "text/plain": [
       "Running query in 'duckdb://'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter-factual Result: {'result': True, 'confidence': 1.5294, 'tension': -26.5807, 'sparsity': 0.9999}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 3. Reasoning & Traceability ---\")\n",
    "# Query: Is Service_A's risk High?\n",
    "query_payload = json.dumps(\n",
    "    {\"head\": \"Service_A\", \"relation\": \"has_risk\", \"tail\": \"High\", \"trace\": True}\n",
    ")\n",
    "result = api.query(query_payload)\n",
    "print(f\"Query Result: {result}\")\n",
    "\n",
    "# Query: Counter-factual (Is Service_A's risk Low?)\n",
    "# Note: We haven't taught it \"Low\", but semantic init might separate High/Low.\n",
    "query_payload_2 = json.dumps(\n",
    "    {\"head\": \"Service_A\", \"relation\": \"has_risk\", \"tail\": \"Low\", \"trace\": True}\n",
    ")\n",
    "result_2 = api.query(query_payload_2)\n",
    "print(f\"Counter-factual Result: {result_2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "soft-kg-example-nb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
